{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "887c905b",
   "metadata": {},
   "source": [
    "# Federated Learning with Flower, PyTorch, and CIFAR-10\n",
    "\n",
    "This notebook demonstrates how to set up a federated learning pipeline using the [Flower](https://flower.dev/) framework with PyTorch and the CIFAR-10 dataset. Federated learning allows multiple clients to collaboratively train a machine learning model while keeping their data local and private.\n",
    "\n",
    "To promote modularity and reusability, the notebook is structured to cleanly separate the components that are shared between centralized and federated training (e.g., model architecture, training logic) from those specific to the federated setup (e.g., client/server logic, simulation). This design makes it easy to benchmark, test, and iterate across training modes.\n",
    "\n",
    "### Notebook Structure\n",
    "\n",
    "1. **Setup and Imports** – Install dependencies and import core libraries.\n",
    "2. **Dataset Preparation** – Load and partition CIFAR-10 using Flower Datasets and IID partitioning.\n",
    "3. **Training and Evaluation Functions** – Define reusable model training and testing logic for both centralized and federated workflows.\n",
    "4. **ClientApp** – Implement a federated Flower client using the shared training/evaluation logic.\n",
    "5. **ServerApp** – Configure the federated learning strategy and server behavior.\n",
    "6. **Simulation** – Run a federated learning simulation across multiple clients.\n",
    "7. **Evaluation** – Evaluate the final global model performance after training.\n",
    "\n",
    "> Note: This notebook uses simulated clients and centralized coordination for demonstration purposes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07a5c91",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "In this section, we install and import the required libraries for our federated learning setup.\n",
    "\n",
    "- **Flower (flwr)**: A framework for building federated learning systems.\n",
    "- **Flower Datasets (flwr_datasets)**: Utilities to download and partition datasets easily.\n",
    "- **PyTorch**: Used for building and training the neural network.\n",
    "- **Predefined CNN model**: Imported from `fedlearn.model`.\n",
    "\n",
    "We will use `FederatedDataset` and `IidPartitioner` from Flower Datasets to partition CIFAR-10 into multiple IID client datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4efec14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 16:17:27.918826: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n",
      "Flower 1.17.0 / PyTorch 2.2.2\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import flwr\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
    "from flwr.server.strategy import FedAvg, FedAdagrad\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr.common import ndarrays_to_parameters, NDArrays, Scalar, Context\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "\n",
    "from fedlearn.model import SmallCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8e6322",
   "metadata": {},
   "source": [
    "## 2. Dataset Preparation\n",
    "\n",
    "In this section, we load and partition the CIFAR-10 dataset using the Flower Datasets library.\n",
    "\n",
    "We perform the following steps:\n",
    "- Download CIFAR-10 using `FederatedDataset`.\n",
    "- Apply standard normalization and transformation.\n",
    "- Use `IidPartitioner` to create IID partitions of the dataset, simulating multiple clients in a federated learning setup.\n",
    "\n",
    "Each partition corresponds to a different client in the federated system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26876dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PARTITIONS = 10 # Number of partitions for the federated dataset same as the number of clients\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "def load_datasets(partition_id: int, num_partitions: int):\n",
    "    fds = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\": num_partitions})\n",
    "    partition = fds.load_partition(partition_id)\n",
    "    # Divide data on each node: 80% train, 20% test\n",
    "    partition_train_test = partition.train_test_split(test_size=0.2, seed=42)\n",
    "    pytorch_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "\n",
    "    def apply_transforms(batch):\n",
    "        # Instead of passing transforms to CIFAR10(..., transform=transform)\n",
    "        # we will use this function to dataset.with_transform(apply_transforms)\n",
    "        # The transforms object is exactly the same\n",
    "        batch[\"img\"] = [pytorch_transforms(img) for img in batch[\"img\"]]\n",
    "        return batch\n",
    "\n",
    "    partition_train_test = partition_train_test.with_transform(apply_transforms)\n",
    "    trainloader = DataLoader(\n",
    "        partition_train_test[\"train\"], batch_size=BATCH_SIZE, shuffle=True\n",
    "    )\n",
    "    valloader = DataLoader(partition_train_test[\"test\"], batch_size=BATCH_SIZE)\n",
    "    testset = fds.load_split(\"test\").with_transform(apply_transforms)\n",
    "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
    "    return trainloader, valloader, testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e769d4e",
   "metadata": {},
   "source": [
    "## 3. Training and Evaluation Functions\n",
    "\n",
    "To support both centralized and federated learning, we define reusable functions for training and evaluating models.\n",
    "\n",
    "These functions can be invoked in two contexts:\n",
    "- Centrally, to train and evaluate a model using all available data (e.g. for benchmarking).\n",
    "- Locally on each federated client, for on-device training and reporting.\n",
    "\n",
    "The training function supports:\n",
    "- Configurable optimizer and hyperparameters\n",
    "- Batch-based model updates\n",
    "\n",
    "The evaluation function returns both loss and accuracy metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da6aa547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "def train(net, trainloader, epochs: int):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for batch in trainloader:\n",
    "            images, labels = batch[\"img\"], batch[\"label\"]\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(net(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in testloader:\n",
    "            images, labels = batch[\"img\"], batch[\"label\"]\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c555a43c",
   "metadata": {},
   "source": [
    "## 4. ClientApp\n",
    "\n",
    "Here we define the Flower client, which encapsulates the logic each federated client uses to train and evaluate the model.\n",
    "\n",
    "Each client performs the following:\n",
    "- Receives global model weights from the server.\n",
    "- Trains the model locally on its own partitioned dataset.\n",
    "- Sends the updated weights back to the server.\n",
    "- Evaluates the global model on its local test data.\n",
    "\n",
    "This class makes use of the shared `train` and `test` functions defined earlier to keep the logic consistent and reusable across different training scenarios.\n",
    "\n",
    "Common customization points:\n",
    "- Adjusting the optimizer configuration inside `train()`.\n",
    "- Changing the number of local training epochs or batch size.\n",
    "- Extending evaluation logic with custom metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85808a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, partition_id, net, trainloader, valloader):\n",
    "        self.partition_id = partition_id\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "def client_fn(context: Context) -> Client:\n",
    "    net = SmallCNN().to(DEVICE)\n",
    "\n",
    "    # Read the node_config to fetch data partition associated to this node\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "\n",
    "    trainloader, valloader, _ = load_datasets(partition_id, num_partitions)\n",
    "    return FlowerClient(partition_id, net, trainloader, valloader).to_client()\n",
    "\n",
    "\n",
    "# Create the ClientApp\n",
    "client = ClientApp(client_fn=client_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e3847f",
   "metadata": {},
   "source": [
    "## 5. ServerApp\n",
    "\n",
    "This section defines the server application using Flower's `server_fn` API. The server is responsible for:\n",
    "\n",
    "- Configuring the federated learning strategy (e.g. FedAvg).\n",
    "- Reading runtime settings such as number of rounds and client participation ratio from a configuration context.\n",
    "- Returning the strategy and configuration needed to run the simulation.\n",
    "\n",
    "This approach makes the server logic highly modular and allows easy injection of config values like `num-server-rounds` or `fraction-fit` during runtime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3866dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the model and get the parameters\n",
    "params = get_parameters(SmallCNN())\n",
    "\n",
    "# The `evaluate` function will be called by Flower after every round\n",
    "def evaluate(\n",
    "    server_round: int,\n",
    "    parameters: NDArrays,\n",
    "    config: Dict[str, Scalar],\n",
    ") -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "    net = SmallCNN().to(DEVICE)\n",
    "    _, _, testloader = load_datasets(0, NUM_PARTITIONS)\n",
    "    set_parameters(net, parameters)  # Update model with the latest parameters\n",
    "    loss, accuracy = test(net, testloader)\n",
    "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
    "    return loss, {\"accuracy\": accuracy}\n",
    "\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    # Create FedAvg strategy\n",
    "    strategy = FedAvg(\n",
    "        fraction_fit=1.0, # Use all clients for training, C\n",
    "        fraction_evaluate=0.5, # Use 50% of clients for evaluation\n",
    "        min_fit_clients=10,  # Minimum number of clients to train\n",
    "        min_evaluate_clients=5,\n",
    "        min_available_clients=NUM_PARTITIONS,\n",
    "        initial_parameters=ndarrays_to_parameters(\n",
    "            params\n",
    "        ),  # Pass initial model parameters\n",
    "        evaluate_fn=evaluate,  # Pass the evaluation function\n",
    "    )\n",
    "\n",
    "    # Configure the server for 3 rounds of training\n",
    "    config = ServerConfig(num_rounds=10)\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n",
    "\n",
    "# Create the ServerApp\n",
    "server = ServerApp(server_fn=server_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5488e440",
   "metadata": {},
   "source": [
    "## 6. Simulation\n",
    "\n",
    "With all components in place, we now simulate the federated learning process using Flower’s `start_simulation` function.\n",
    "\n",
    "This includes:\n",
    "- Initializing each client with its own data partition.\n",
    "- Launching multiple client instances in parallel using `ClientApp`.\n",
    "- Running the simulation across a specified number of federated rounds.\n",
    "\n",
    "We control how many clients participate per round and how many rounds of training we perform.\n",
    "\n",
    "Common configuration options:\n",
    "- Number of clients in the federation\n",
    "- Number of training rounds\n",
    "- Client resources (e.g., number of CPUs or GPUs per client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78414882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=10, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 0.07212714471817017, {'accuracy': 0.1}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.07212714471817017 / accuracy 0.1\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 2] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.06415555626153946, accuracy 0.23225\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 1] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 3] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.061751481145620346, accuracy 0.26675\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 4] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 6] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.06224852427840233, accuracy 0.255\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 5] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 7] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.06254737079143524, accuracy 0.258\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 8] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 9] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.06276913732290268, accuracy 0.26325\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.06173369660973549, accuracy 0.27825\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 0] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 0.06560525085926056, {'accuracy': 0.3404}, 365.18228058800014)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.06560525085926056 / accuracy 0.3404\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.06366998702287674, accuracy 0.23775\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 5] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 9] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 0] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.05433623492717743, accuracy 0.36\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 1] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 4] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.05413322150707245, accuracy 0.35875\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 3] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 6] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.05239522457122803, accuracy 0.38225\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 5] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 8] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.05344279110431671, accuracy 0.3725\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 9] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 2] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.05303775146603584, accuracy 0.37625\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 7] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, 0.04772388617992401, {'accuracy': 0.4513}, 578.7893392780024)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.04772388617992401 / accuracy 0.4513\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.05368991941213608, accuracy 0.366\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 4] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 0] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 8] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.04838968440890312, accuracy 0.4325\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 1] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 8] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.04964575171470642, accuracy 0.4125\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.04816494882106781, accuracy 0.4265\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 2] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 4] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.0476052351295948, accuracy 0.4375\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.04835527017712593, accuracy 0.427\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 6] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 7] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.04755359888076782, accuracy 0.43675\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.04787081480026245, accuracy 0.427\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 9] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 3] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.04694034159183502, accuracy 0.4485\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 5] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (3, 0.04267010600566864, {'accuracy': 0.5012}, 780.9744502670001)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.04267010600566864 / accuracy 0.5012\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.04827620089054108, accuracy 0.41925\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 6] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 9] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 0] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.045357100665569305, accuracy 0.467\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 1] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 3] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.04356422647833824, accuracy 0.4965\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 4] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 5] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.045411594212055206, accuracy 0.4585\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 6] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 7] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.044101107865571976, accuracy 0.4775\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 8] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 2] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.04438985511660576, accuracy 0.4785\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 9] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (4, 0.04004537639021873, {'accuracy': 0.5376}, 1010.758744316001)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.04004537639021873 / accuracy 0.5376\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.04399628937244415, accuracy 0.48625\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 8] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 0] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.04306266829371452, accuracy 0.503\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 1] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 2] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.042174797505140305, accuracy 0.5065\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 3] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 7] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.0419757254421711, accuracy 0.50825\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 6] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 8] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.041608329862356186, accuracy 0.5105\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 9] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 4] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.042044706642627716, accuracy 0.503\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 5] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (5, 0.03774632310271263, {'accuracy': 0.5675}, 1163.4009377289985)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.03774632310271263 / accuracy 0.5675\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.04263540357351303, accuracy 0.511\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 9] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 1] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.04082265868782997, accuracy 0.535\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 0] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 2] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.0404006689786911, accuracy 0.5305\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 4] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 5] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.04044705256819725, accuracy 0.52625\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 6] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 7] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.040488459169864655, accuracy 0.5245\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 8] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 3] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.038813743740320206, accuracy 0.549\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 9] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (6, 0.035877309077978134, {'accuracy': 0.5853}, 1304.986805722001)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.035877309077978134 / accuracy 0.5853\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.039495304226875305, accuracy 0.5395\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 4] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 9] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 0] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.038402702659368515, accuracy 0.562\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 1] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 2] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.0377005934715271, accuracy 0.5545\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 4] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 5] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.03849959000945091, accuracy 0.551\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 7] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 9] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.037367336452007294, accuracy 0.569\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 8] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 3] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.0368688702583313, accuracy 0.575\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 6] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (7, 0.034131983011960985, {'accuracy': 0.606}, 1447.2098903939986)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.034131983011960985 / accuracy 0.606\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.037061966955661774, accuracy 0.5665\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 9] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 1] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.03698710724711418, accuracy 0.58625\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 0] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 4] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.036584898829460144, accuracy 0.5845\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 3] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 6] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.035253480076789856, accuracy 0.594\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 7] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 9] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.03604304790496826, accuracy 0.5885\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 8] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 2] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.0362326055765152, accuracy 0.58\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 5] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (8, 0.03255206167697906, {'accuracy': 0.629}, 1591.5922650799985)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.03255206167697906 / accuracy 0.629\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.036690592765808105, accuracy 0.58025\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 9] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 1] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.0356384702026844, accuracy 0.60525\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 0] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 2] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.033828407526016235, accuracy 0.61375\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 3] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 6] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.03487655147910118, accuracy 0.5965\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.03379723057150841, accuracy 0.6085\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 4] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 8] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.035258106887340546, accuracy 0.5975\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.03400592505931854, accuracy 0.6105\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 9] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 5] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.034111734479665756, accuracy 0.6025\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.03507180139422417, accuracy 0.593\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 7] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.03460133820772171, accuracy 0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (9, 0.0316769840657711, {'accuracy': 0.6398}, 1740.5354026849964)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.0316769840657711 / accuracy 0.6398\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 0] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.03348590061068535, accuracy 0.615\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 1] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 2] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.03312801197171211, accuracy 0.6195\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 4] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 6] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.03168560191988945, accuracy 0.63125\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 7] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 8] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.03256351500749588, accuracy 0.62675\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 9] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 3] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m Epoch 1: train loss 0.03355220705270767, accuracy 0.609\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 5] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (10, 0.03029168615937233, {'accuracy': 0.6545}, 1866.7559994830008)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.03029168615937233 / accuracy 0.6545\n",
      "\u001b[36m(ClientAppActor pid=13968)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m Epoch 1: train loss 0.03189672529697418, accuracy 0.63975\n",
      "\u001b[36m(ClientAppActor pid=13967)\u001b[0m [Client 6] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 10 round(s) in 1879.98s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.06726358551979064\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.048949416160583493\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.044867719125747677\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.0412010176897049\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.038646753573417666\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 6: 0.038089262795448296\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 7: 0.0359983600139618\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 8: 0.0340536669254303\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 9: 0.03263024712800979\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 10: 0.031005680131912232\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 0: 0.07212714471817017\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.06560525085926056\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.04772388617992401\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.04267010600566864\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.04004537639021873\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.03774632310271263\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 6: 0.035877309077978134\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 7: 0.034131983011960985\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 8: 0.03255206167697906\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 9: 0.0316769840657711\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 10: 0.03029168615937233\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(0, 0.1),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (1, 0.3404),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (2, 0.4513),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (3, 0.5012),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (4, 0.5376),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (5, 0.5675),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (6, 0.5853),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (7, 0.606),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (8, 0.629),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (9, 0.6398),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (10, 0.6545)]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    }
   ],
   "source": [
    "\n",
    "NUM_PARTITIONS = 10  # Number of partitions (clients)\n",
    "run_simulation(\n",
    "    server_app=server, client_app=client, num_supernodes=NUM_PARTITIONS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfc2dac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
