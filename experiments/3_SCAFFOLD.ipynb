{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f9c779e",
   "metadata": {},
   "source": [
    "# SCAFFOLD for Non-IID Setting \n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook we implement the SCAFFOLD algorithm, as proposed by Karimireddy et al. in the paper [SCAFFOLD: Stochastic Controlled Averaging for Federated Learning](https://proceedings.mlr.press/v119/karimireddy20a/karimireddy20a.pdf) in 2020. The general idea is to introduce control variates to the local model updates, in order to mitigate the effects that data heterogeneity has on the learning process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "095c5c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import List, Tuple, Optional, Union, Dict\n",
    "import os\n",
    "from pathlib import Path\n",
    "from logging import WARNING, WARN, INFO, DEBUG\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "\n",
    "import flwr\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    Parameters,\n",
    "    Context, \n",
    "    Code,\n",
    "    Scalar, \n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    "    )\n",
    "from flwr.common.typing import GetParametersIns\n",
    "from flwr.common.logger import log\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents, Server\n",
    "from flwr.server.strategy import Strategy, FedAvg\n",
    "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.client_manager import ClientManager, SimpleClientManager\n",
    "from flwr.server.server import FitResultsAndFailures, fit_clients\n",
    "from flwr.simulation import run_simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf16d73",
   "metadata": {},
   "source": [
    "Next, we need to make some imports from our own package. We will import the ```SmallCNN``` neural net object, as this is what we are running all the tests with. We will also import the function ```load_datasets```, which returns a tuple of ```(trainloader,valloader,testloader)```. We will again make use of the ```test``` function, which was introduced in the previous notebook, as well as some utility functions ```get_parameters``` and ```set_parameters```. Feel free to revisit the code, or you can simply use the python function ```help``` (eg ```help(test)```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9125547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedlearn.model import SmallCNN, test\n",
    "from fedlearn.data_loader import load_datasets\n",
    "from fedlearn.utils import set_parameters, get_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9868430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_datasets in module fedlearn.data_loader:\n",
      "\n",
      "load_datasets(partition_id: int, partition_method: str, partitioner_kwargs: Dict[str, Union[str, int, float]], batch_size: int = 64, cache_dir: str = 'data') -> Tuple[torch.utils.data.dataloader.DataLoader, torch.utils.data.dataloader.DataLoader, torch.utils.data.dataloader.DataLoader]\n",
      "    function for loading CIFAR-10 dataset and partitioning it for federated learning.\n",
      "    \n",
      "    Parameters:\n",
      "        partition_id:       int, the ID of the partition to load.\n",
      "        partition_method:   str, the method to use for partitioning the dataset.\n",
      "        partitioner_kwargs: Dict[str, Union[str, int, float]], the parameters for the partitioner.\n",
      "        batch_size:         int, the size of each batch for training and validation.\n",
      "        cache_dir:          str, the directory to cache the dataset.\n",
      "        \n",
      "    Returns:\n",
      "        Tuple[DataLoader, DataLoader, DataLoader]: trainloader, valloader, and testloader.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(load_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3e0686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = Path().cwd().parent / \"data\" / \"flower_dataset\"       # specify your data directory\n",
    "LOGDIR = Path().cwd().parent / \"logs\" / \"scaffold\"              # specify your log directory\n",
    "\n",
    "# creates the log directory if it does not exist\n",
    "if not LOGDIR.exists():\n",
    "    LOGDIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "002a2a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "Flower 1.18.0 / PyTorch 2.7.0+cu126\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # if running on mac, use: \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "disable_progress_bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f28775c",
   "metadata": {},
   "source": [
    "We are now ready to specify some simulation parameters. We arbitrarily set the number of clients/partitions to 10, specify a batch size of 64, and choose the dirichlet method for partitioning the data, with $\\alpha=0.5$. For other data partitioning schemes, we encourage you to have a look at the ```flwr_datasets``` documentation on partitioners [here](https://flower.ai/docs/datasets/ref-api/flwr_datasets.partitioner.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e393fec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since cifar10 couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at c:\\Users\\Phill\\Documents\\School\\MSc\\3. Sem\\Federated Learning\\FedLearning-Final\\data\\flower_dataset\\cifar10\\plain_text\\0.0.0\\0b2714987fa478483af9968de7c934580d0bb9a2 (last modified on Wed Jun  4 13:48:33 2025).\n"
     ]
    }
   ],
   "source": [
    "NUM_PARTITIONS = 10 # Number of partitions for the federated dataset same as the number of clients\n",
    "BATCH_SIZE = 64\n",
    "PARTITION_METHOD = \"dirichlet\"  # Options: \"iid\", \"dirichlet\", \"shard\"\n",
    "PARTITIONER_KWARGS = {\n",
    "    \"num_partitions\": NUM_PARTITIONS,   # Number of partitions to create\n",
    "    \"alpha\": 0.5,                       # Dirichlet parameter, only used if partition_method is \"dirichlet\"\n",
    "    \"partition_by\": \"label\"             # Partition by label, only used if partition_method is \"dirichlet\" or \"shard\"\n",
    "}\n",
    "\n",
    "# Load datasets for partition 0 to check if everything works\n",
    "_, _, _ = load_datasets(\n",
    "    partition_id=0,                         # specify partition ID to load\n",
    "    partition_method=PARTITION_METHOD,      # Method to partition the dataset\n",
    "    partitioner_kwargs=PARTITIONER_KWARGS,  # Parameters for the partitioner\n",
    "    batch_size=BATCH_SIZE,                  # Batch size for the DataLoader    \n",
    "    cache_dir=DATADIR                       # Directory to cache the datasets\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbbce0a",
   "metadata": {},
   "source": [
    "### Define Scaffold Optimizer\n",
    "\n",
    "Recall that the local update in Scaffold is given by\n",
    "\n",
    "$$\n",
    "w^{(i)} \\gets w^{(i)} - \\eta_l \\left( g_i(w^{(i)}) + c - c_i \\right)\n",
    "$$\n",
    "\n",
    "Which can be seen as a gradient correction to Stochastic Gradient Descent (SGD). We may therefore extend the pytorch ```SGD``` class. We do this by computing the the regular SGD step, then adding the correction manually:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "w^{(i)} &\\gets w^{(i)} - \\eta_l \\, g_i\\left(w^{(i)}\\right) \\\\\n",
    "w^{(i)} &\\gets w^{(i)} - \\eta_l (c - c_i)\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b999b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaffoldOptimizer(SGD):\n",
    "    \"\"\"\n",
    "    Extension of the SGD optimizer for the Scaffold algorithm.\n",
    "    This optimizer applies a correction term based on the global \n",
    "    and client control variables. \n",
    "    \"\"\"\n",
    "    def __init__(self, params, lr, momentum=0., weight_decay=0.):\n",
    "        super().__init__(params, lr, momentum, weight_decay)\n",
    "\n",
    "    def step_custom(self, global_cv, client_cv):\n",
    "        \"\"\"\n",
    "        Perform a single optimization step.\n",
    "        :param global_cv: Global control variable\n",
    "        :param client_cv: Client control variable\n",
    "        \"\"\"\n",
    "        # compute regular SGD step\n",
    "        #   w <- w - lr * grad\n",
    "        super().step() \n",
    "\n",
    "        # now add the correction term\n",
    "        #   w <- w - lr * (g_cv - c_cv)\n",
    "        device = self.param_groups[0][\"params\"][0].device\n",
    "        for group in self.param_groups:\n",
    "            for param, g_cv, c_cv in zip(group[\"params\"], global_cv, client_cv):\n",
    "                # here we add the correction term to each parameter tensor.\n",
    "                # the alpha value scales the correction term\n",
    "                    g_cv, c_cv = g_cv.to(device), c_cv.to(device)\n",
    "                    param.data.add_(g_cv - c_cv, alpha=-group[\"lr\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0954175b",
   "metadata": {},
   "source": [
    "As in the previous notebook, we need to implement a ```train``` function that performs the local update for a client. As the control variates are needed for the correction step, we cannot simply reuse the function from the previous notebook. Therefore, we need to implement a similar function, that takes the control variates into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "862d0b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_scaffold(net: torch.nn.Module, \n",
    "                   device: torch.device, \n",
    "                   trainloader: torch.utils.data.DataLoader,\n",
    "                   criterion: nn.Module,\n",
    "                   num_epochs: int, \n",
    "                   lr: float, \n",
    "                   momentum: float, \n",
    "                   weight_decay: float, \n",
    "                   global_cv: List[torch.Tensor], \n",
    "                   client_cv: List[torch.Tensor],\n",
    "                   ) -> None:\n",
    "    \"\"\"\n",
    "    Function that trains a model using the Scaffold optimization algorithm.\n",
    "    Parameters:\n",
    "        net:            The neural network model to train.\n",
    "        device:         The device to run the training on (CPU or GPU).\n",
    "        trainloader:    DataLoader for the training data.\n",
    "        criterion:      Loss function to use for training.\n",
    "        num_epochs:     Number of epochs to train the model.\n",
    "        lr:             Learning rate for the optimizer.\n",
    "        momentum:       Momentum factor for the optimizer.\n",
    "        weight_decay:   Weight decay (L2 penalty) for the optimizer.\n",
    "        global_cv:      Global control variables for Scaffold.\n",
    "        client_cv:      Client control variables for Scaffold.\n",
    "    \"\"\"\n",
    "    net.to(device)\n",
    "    net.train()\n",
    "\n",
    "    # initialize the custom Scaffold optimizer\n",
    "    optimizer = ScaffoldOptimizer(\n",
    "        net.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay\n",
    "    )\n",
    "    \n",
    "    for _ in range(num_epochs):\n",
    "        for batch in trainloader:\n",
    "            Xtrain, Ytrain = batch[\"img\"].to(device), batch[\"label\"].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = net(Xtrain)\n",
    "            loss = criterion(output, Ytrain)\n",
    "\n",
    "            loss.backward()\n",
    "            \n",
    "            # Perform a single optimization step with the control variables\n",
    "            optimizer.step_custom(global_cv, client_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26148887",
   "metadata": {},
   "source": [
    "Now we get to the difficult part. As is the previous notebook, we need to define a custom client class for the flower framework. However, as the algorithm requires aggregation and storage of a global control variate as well, we must also implement both the aggregation class, called a ```Strategy```, as well as the server class, called a ```Server```, from scratch.\n",
    "\n",
    "We will start with the client class, as we are most familiar with this. Below are some important considerations:\n",
    "\n",
    "1. We can inherit the  ```NumPyClient``` class from the flower framework, however we need to remember to convert between ```np.ndarray``` and ```torch.tensor``` before and after local updates.\n",
    "2. There are 3 methods we need to implement, with a predefined structure\n",
    "   1. ```fit()```\n",
    "   2. ```get_parameters()```\n",
    "   3. ```evaluate()```\n",
    "\n",
    "The ```fit()``` method takes 2 parameters, ```parameters```, which in our case will be the concatenated global model parameters and the global control variate, and ```config```, which we will ignore for now. This method is responsible for all client-side updates, which means that we will call the ```train_scaffold``` function inside it to perform the local model update, as well as computing the updated local control variate. We will update the local control variate according to Option II from the original paper, which is given by:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "c_i^+ \\gets c_i - c + \\frac{1}{K \\eta_l}(w_t - w_{t+1}^{(i)}) \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Where $K$ is the number of of descent steps taken, ie number of epochs times the number of mini-batches. \n",
    "\n",
    "We also need to specify what exactly is returned by the method. For clarity and in order to remain close in notation to the original paper, we will return the difference between the input model parameters and the locally updated parameters (returned from ```train_scaffold```), concatenated with the difference between the new and previous local control variate. Concretely, we return\n",
    "\n",
    "$$\n",
    "[w_{t+1}^{(i)} - w_t,\\,\\, c_i^+ - c_i]\n",
    "$$\n",
    "\n",
    "This is due to how the server-side updates look:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "   w_{t+1} &\\gets w_t + \\frac{\\eta_g}{|\\mathcal{S}|} \\sum_{i \\in \\mathcal{S}} \\frac{n^{(i)}}{n}(w_{t+1}^{(i)} - w_t) \\\\\n",
    "   c &\\gets c + \\frac{1}{N} \\sum_{i \\in \\mathcal{S}} \\frac{n^{(i)}}{n}(c_i^+ - c_i)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f6d009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaffoldClient(NumPyClient):\n",
    "    def __init__(self, \n",
    "                 partition_id: int, \n",
    "                 net: torch.nn.Module, \n",
    "                 trainloader: torch.utils.data.DataLoader, \n",
    "                 valloader: torch.utils.data.DataLoader,\n",
    "                 criterion: nn.Module,\n",
    "                 device: torch.device,\n",
    "                 num_epochs: int,\n",
    "                 lr: float,\n",
    "                 momentum: float,\n",
    "                 weight_decay: float,\n",
    "                 save_dir: Optional[str] = None,\n",
    "                 ):\n",
    "        self.partition_id = partition_id\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        self.num_epochs = num_epochs\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        # define directory to save client control variates\n",
    "        if save_dir is None:\n",
    "            save_dir = \"client_cvs\"\n",
    "\n",
    "        # create directory if it does not exist\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        # define the path to save the client control variates\n",
    "        self.save_name = os.path.join(save_dir, f\"client_{self.partition_id}_cv.pt\")\n",
    "\n",
    "        # initialize client control variates\n",
    "        self.client_cv = [torch.zeros(param.shape).to(torch.float32) for param in self.net.state_dict().values()]\n",
    "\n",
    "\n",
    "    # Here is where all the training logic and control variate updates happen\n",
    "    def fit(self, parameters: List[np.ndarray], config: dict) -> Tuple[List[np.ndarray], int, dict]:\n",
    "\n",
    "        # the global parameters are packed together with the global control variates\n",
    "        # in the form [params, global_cv]. we start by separating them\n",
    "        params = parameters[:len(parameters) // 2]          # list of np.ndarray\n",
    "        global_cv = parameters[len(parameters) // 2:]       # list of np.ndarray\n",
    "\n",
    "        # load the current global model:\n",
    "        set_parameters(self.net, params)\n",
    "\n",
    "        # load client control variates, if they exist:\n",
    "        if os.path.exists(self.save_name):\n",
    "            self.client_cv = torch.load(self.save_name)     # list of torch.tensor\n",
    "\n",
    "        # convert global control variates to tensors\n",
    "        global_cv_torch = [torch.tensor(cv).to(torch.float32) for cv in global_cv]  # list of torch.tensor\n",
    "\n",
    "        # call the training function\n",
    "        train_scaffold(\n",
    "            net=self.net,\n",
    "            device=self.device,\n",
    "            trainloader=self.trainloader,\n",
    "            criterion=self.criterion,\n",
    "            num_epochs=self.num_epochs,\n",
    "            lr=self.lr,\n",
    "            momentum=self.momentum,\n",
    "            weight_decay=self.weight_decay,\n",
    "            global_cv=global_cv_torch,          # passing list of torch.tensor\n",
    "            client_cv=self.client_cv            # passing list of torch.tensor\n",
    "        )\n",
    "\n",
    "        # update the client control variates\n",
    "        yi = get_parameters(self.net)           # list of np.ndarray\n",
    "\n",
    "        # compute coefficient for the control variates\n",
    "        # 1 / (K * eta) where K is the number of backward passes (num_epochs * len(trainloader))\n",
    "        coeff = 1. / (self.num_epochs * len(self.trainloader) * self.lr) \n",
    "\n",
    "        client_cv = [cv.numpy() for cv in self.client_cv]  # list of np.ndarray\n",
    "\n",
    "        # define new list for udated client control variates\n",
    "        client_cv_new = []\n",
    "\n",
    "        # compute client control variate update according to eq (1), list of np.ndarray\n",
    "        for xj, yj, cj, cij in zip(params, yi, global_cv, client_cv):\n",
    "            client_cv_new.append(\n",
    "                cij - cj + coeff * (xj - yj)\n",
    "            ) \n",
    "\n",
    "        # compute server updates\n",
    "        server_update_x = [yj - xj for xj, yj in zip(params, yi)]\n",
    "        server_update_c = [cij_n - cij for cij_n, cij in zip(client_cv_new, client_cv)]\n",
    "\n",
    "        # convert client cvs back to torch tensors\n",
    "        self.client_cv = [torch.tensor(cv).to(torch.float32) for cv in client_cv_new]  \n",
    "\n",
    "        # save the updated client control variates\n",
    "        torch.save(self.client_cv, self.save_name)\n",
    "\n",
    "        #concatenate server updates\n",
    "        server_update = server_update_x + server_update_c\n",
    "\n",
    "        return server_update, len(self.trainloader.dataset), {}\n",
    "\n",
    "\n",
    "    def get_parameters(self, config: dict) -> List[np.ndarray]:\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "\n",
    "    def evaluate(self, parameters: List[np.ndarray], config: dict) -> Tuple[float, int, dict]:\n",
    "        set_parameters(self.net, parameters)\n",
    "        avg_loss, accuracy = test(\n",
    "            net=self.net,\n",
    "            device=self.device,\n",
    "            testloader=self.valloader,\n",
    "            criterion=self.criterion\n",
    "        )\n",
    "        return float(avg_loss), len(self.valloader), {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7644bf3c",
   "metadata": {},
   "source": [
    "Now that we have the flower client defined, we need to define a constructor function which the flower framework can use to instatiate clients as it goes. This is done similarly to in the previous notebook. It should be noted that all the simulation parameters, such as ```partition_method```, ```batch_size``` etc. can be passed to the ```client_fn``` function thru the context. This is useful when simulations are run from the command line. For now, we will ignore this, and hardcode it into the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fc2badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_fn(context: Context) -> Client:\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "\n",
    "    partitioner_kwargs = {\n",
    "        \"num_partitions\": num_partitions,   # Number of partitions to create\n",
    "        \"alpha\": 0.5,                       # Dirichlet parameter\n",
    "        \"partition_by\": \"label\"             # Partition by label\n",
    "    }\n",
    "\n",
    "    trainloader, valloader, _ = load_datasets(\n",
    "        partition_id=partition_id,              # specify partition ID to load\n",
    "        partition_method=PARTITION_METHOD,      # Method to partition the dataset\n",
    "        partitioner_kwargs=partitioner_kwargs,  # Parameters for the partitioner\n",
    "        batch_size=BATCH_SIZE,                  # Batch size for the DataLoader    \n",
    "        cache_dir=DATADIR                       # Directory to cache the datasets\n",
    "    )\n",
    "\n",
    "    net = SmallCNN().to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Define hyperparameters for training\n",
    "    num_epochs = 5\n",
    "    lr = 1e-2\n",
    "    momentum = 0.\n",
    "    weight_decay = 0.\n",
    "\n",
    "    return ScaffoldClient(\n",
    "        partition_id=partition_id,\n",
    "        net=net,\n",
    "        trainloader=trainloader,\n",
    "        valloader=valloader,\n",
    "        criterion=criterion,\n",
    "        device=DEVICE,\n",
    "        num_epochs=num_epochs,\n",
    "        lr=lr,\n",
    "        momentum=momentum,\n",
    "        weight_decay=weight_decay,\n",
    "        save_dir=LOGDIR / \"client_cvs\"\n",
    "    ).to_client()\n",
    "\n",
    "\n",
    "client = ClientApp(client_fn=client_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661d41df",
   "metadata": {},
   "source": [
    "Now we are ready to define our strategy. This looks complex on the surface, however the really key component here is the ```aggregate_fit()``` method. This method expects 3 input parameters:\n",
    "\n",
    "1. server_round: This parameter is not important to us right now.\n",
    "2. results: This is a list of tuples, containing ```(ClientProxy,FitRes)```. We are only interested in the ```FitRes```, which presumably is short for \"Fit results\". This is a class that contains 2 attributes that we are interested in: ```parameters```, which contains the concatenated model parameters and local control variates, as returned by the ```fit()``` method of the ```ScaffoldClient```, and ```num_examples```, which contains how many datapoints the client has. \n",
    "3. failures: similar to results in datatype, but can also contain exceptions in the list. As we are concerned with simulations where we expect all clients to behave regularly, this can be ignored for now.\n",
    "\n",
    "In this method, we are only concerned with \"aggregating\" the results, and not the full global update (confusing I know). This amounts to computing purely the sum portion of the global updates (both model parameters and global control variate). The server will be responsible for the full update.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53151c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaffoldStrategy(Strategy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        total_num_clients: int,\n",
    "        fraction_fit: float = 1.0,\n",
    "        fraction_evaluate: float = 1.0,\n",
    "        min_fit_clients: int = 2,\n",
    "        min_evaluate_clients: int = 2,\n",
    "        min_available_clients: int = 2,\n",
    "        evaluate_fn: Optional[callable] = None,\n",
    "        accept_failures: bool = False,\n",
    "        fit_metrics_aggregation_fn: Optional[callable] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.total_num_clients = total_num_clients\n",
    "        self.fraction_fit = fraction_fit\n",
    "        self.fraction_evaluate = fraction_evaluate\n",
    "        self.min_fit_clients = min_fit_clients\n",
    "        self.min_evaluate_clients = min_evaluate_clients\n",
    "        self.min_available_clients = min_available_clients\n",
    "        self.evaluate_fn = evaluate_fn\n",
    "        self.accept_failures = accept_failures\n",
    "        self.fit_metrics_aggregation_fn = fit_metrics_aggregation_fn\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"ScaffoldStrategy\"\n",
    "\n",
    "\n",
    "    def initialize_parameters(\n",
    "        self, \n",
    "        client_manager: ClientManager\n",
    "    ) -> Optional[Parameters]:\n",
    "        \"\"\"Initialize global model parameters.\"\"\"\n",
    "        net = SmallCNN()\n",
    "        parameters = get_parameters(net)        \n",
    "        return ndarrays_to_parameters(parameters)\n",
    "\n",
    "\n",
    "    def configure_fit(\n",
    "        self, \n",
    "        server_round: int, \n",
    "        parameters: Parameters, \n",
    "        client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
    "        \"\"\"\n",
    "        Configure the next round of training. Samples clients for \n",
    "        training and defines the configurations for them. This\n",
    "        method is called by the server.\n",
    "        \"\"\"\n",
    "\n",
    "        config = {}\n",
    "        fit_ins = FitIns(parameters, config)\n",
    "\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_fit_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "\n",
    "        fit_configurations = [(client, fit_ins) for client in clients]\n",
    "        \n",
    "        return fit_configurations\n",
    "\n",
    "\n",
    "    def aggregate_fit(\n",
    "        self, \n",
    "        server_round: int, \n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        \"\"\"\n",
    "        aggregation method for Scaffold strategy. Due to how \n",
    "        the ScaffoldClient returns the parameters for the global\n",
    "        update, we can reuse the \"aggregate\" function from \n",
    "        flwr.server.strategy.aggregate (FedAvg aggregation).\n",
    "        \"\"\"\n",
    "        if not results:\n",
    "            return None, {}\n",
    "        if not self.accept_failures and failures:\n",
    "            return None, {}\n",
    "        \n",
    "        combined_parameters = [\n",
    "            parameters_to_ndarrays(fit_res.parameters) for _, fit_res in results\n",
    "        ]\n",
    "\n",
    "        num_samples_all = [fit_res.num_examples for _, fit_res in results]  # number of training samples from each client\n",
    "\n",
    "        aggregation_inputs = [\n",
    "            (local_params, num_samples)\n",
    "            for local_params, num_samples in zip(combined_parameters, num_samples_all)\n",
    "        ]\n",
    "        aggregated_parameters = aggregate(aggregation_inputs)\n",
    "\n",
    "        metrics_aggregated = {}\n",
    "        if self.fit_metrics_aggregation_fn is not None:\n",
    "            fit_metrics = [\n",
    "                (fit_res.num_examples, fit_res.metrics)\n",
    "                for _, fit_res in results\n",
    "            ]\n",
    "            metrics_aggregated = self.fit_metrics_aggregation_fn(fit_metrics)\n",
    "        elif server_round == 1:\n",
    "            log(WARNING, \"No fit_metrics_aggregation_fn provided\")\n",
    "        \n",
    "        return (\n",
    "            ndarrays_to_parameters(aggregated_parameters),\n",
    "            metrics_aggregated,\n",
    "        )\n",
    "\n",
    "\n",
    "    def configure_evaluate(\n",
    "        self, \n",
    "        server_round: int, \n",
    "        parameters: Parameters, \n",
    "        client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
    "        \"\"\"Configure the next round of evaluation.\"\"\"\n",
    "        if self.fraction_evaluate == 0.0:\n",
    "            return []\n",
    "        config = {}\n",
    "        evaluate_ins = EvaluateIns(parameters, config)\n",
    "\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_evaluation_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "\n",
    "        # Return client/config pairs\n",
    "        return [(client, evaluate_ins) for client in clients]\n",
    "\n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
    "\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        loss_aggregated = weighted_loss_avg(\n",
    "            [\n",
    "                (evaluate_res.num_examples, evaluate_res.loss)\n",
    "                for _, evaluate_res in results\n",
    "            ]\n",
    "        )\n",
    "        metrics_aggregated = {}\n",
    "        return loss_aggregated, metrics_aggregated\n",
    "\n",
    "\n",
    "    # method for evaluating the global model\n",
    "    def evaluate(\n",
    "            self, \n",
    "            server_round: int, \n",
    "            parameters: Parameters\n",
    "        ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        \"\"\"\n",
    "        Evaluate global model parameters using an evaluation function.\n",
    "        \"\"\"\n",
    "        if self.evaluate_fn is None:\n",
    "            return None\n",
    "            # If an evaluation function is provided, use it\n",
    "        parameters_ndarray = parameters_to_ndarrays(parameters)\n",
    "        eval_res = self.evaluate_fn(server_round, parameters_ndarray, {})\n",
    "        if eval_res is None:\n",
    "            return None\n",
    "        loss, metrics = eval_res\n",
    "        return loss, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81abe551",
   "metadata": {},
   "source": [
    "Finally, we are ready to define the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f172f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_params(\n",
    "        parameters: Parameters, \n",
    "        global_cv: List[np.ndarray]\n",
    "    ) -> Parameters:\n",
    "    \"\"\"\n",
    "    Concatenate model parameters and global control variates.\n",
    "    \"\"\"\n",
    "    parameters_ndarrays = parameters_to_ndarrays(parameters)\n",
    "    parameters_ndarrays.extend(global_cv)\n",
    "    return ndarrays_to_parameters(parameters_ndarrays)\n",
    "\n",
    "\n",
    "class ScaffoldServer(Server):\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            strategy: Strategy, \n",
    "            client_manager: Optional[ClientManager] = None,\n",
    "        ) -> None:\n",
    "        \n",
    "        if client_manager is None:\n",
    "            client_manager = SimpleClientManager()\n",
    "\n",
    "        super().__init__(strategy=strategy, client_manager=client_manager)\n",
    "        \n",
    "        self.global_cv: List[np.ndarray] = []  # Global control variates for Scaffold\n",
    "    \n",
    "    def _get_initial_parameters(\n",
    "            self, \n",
    "            server_round: int, \n",
    "            timeout: Optional[float]\n",
    "        ) -> Parameters: \n",
    "        \n",
    "        parameters: Optional[Parameters] = self.strategy.initialize_parameters(\n",
    "            self.client_manager\n",
    "        )\n",
    "    \n",
    "        if parameters is not None:\n",
    "            log(INFO, \"Using initial parameters provided by strategy\")\n",
    "        else:\n",
    "            # Get initial parameters from one of the clients\n",
    "            log(INFO, \"Requesting initial parameters from one random client\")\n",
    "            random_client = self._client_manager.sample(1)[0]\n",
    "            ins = GetParametersIns(config={})\n",
    "            get_parameters_res = random_client.get_parameters(\n",
    "                ins=ins, timeout=timeout, group_id=server_round\n",
    "            )\n",
    "            if get_parameters_res.status.code == Code.OK:\n",
    "                log(INFO, \"Received initial parameters from one random client\")\n",
    "            else:\n",
    "                log(\n",
    "                    WARN,\n",
    "                    \"Failed to receive initial parameters from the client.\"\n",
    "                    \" Empty initial parameters will be used.\",\n",
    "                )\n",
    "            parameters = get_parameters_res.parameters\n",
    "            \n",
    "        self.global_cv = [\n",
    "                np.zeros_like(param, dtype=np.float32) for param in parameters_to_ndarrays(parameters)\n",
    "            ]\n",
    "        \n",
    "        return parameters\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def fit_round(\n",
    "            self,\n",
    "            server_round: int,\n",
    "            timeout: Optional[float],\n",
    "        ) -> Optional[Tuple[Optional[Parameters], Dict[str, Scalar], FitResultsAndFailures]]:\n",
    "        \n",
    "        # define client instructions to be passed to \"fit_clients\" function\n",
    "        client_instructions = self.strategy.configure_fit(\n",
    "            server_round=server_round,\n",
    "            parameters=concat_params(self.parameters, self.global_cv),\n",
    "            client_manager=self._client_manager,\n",
    "        )\n",
    "\n",
    "        # if no clients are selected, return None\n",
    "        if not client_instructions:\n",
    "            log(INFO, f\"fit_round {server_round}: no clients selected.\")\n",
    "            return None\n",
    "        \n",
    "        log(\n",
    "            DEBUG,\n",
    "            f\"fit_round {server_round}: selected {len(client_instructions)} clients.\",\n",
    "        )\n",
    "\n",
    "        # Call the \"fit_clients\" function to perform the training on selected clients\n",
    "        results, failures = fit_clients(\n",
    "            client_instructions=client_instructions,\n",
    "            max_workers=self.max_workers,\n",
    "            timeout=timeout,\n",
    "            group_id=server_round,\n",
    "        )\n",
    "\n",
    "        log(\n",
    "            DEBUG,\n",
    "            f\"fit_round {server_round}: received {len(results)} results and {len(failures)} failures.\",\n",
    "        )\n",
    "\n",
    "        # Aggregate the results from the clients\n",
    "        aggregated_results = self.strategy.aggregate_fit(\n",
    "            server_round=server_round,\n",
    "            results=results,\n",
    "            failures=failures,\n",
    "        )\n",
    "\n",
    "        # Extract the aggregated parameters and control variates\n",
    "        aggregated_results_combined = []\n",
    "        if aggregated_results[0] is not None:\n",
    "            aggregated_results_combined = parameters_to_ndarrays(aggregated_results[0])\n",
    "\n",
    "        # Split the aggregated results into model parameters and control variates\n",
    "        aggregated_parameters = aggregated_results_combined[:len(aggregated_results_combined) // 2] # model parameters\n",
    "        aggregated_cv = aggregated_results_combined[len(aggregated_results_combined) // 2:]         # control variates\n",
    "\n",
    "        # define the update coefficient for the control variates\n",
    "        cv_coeff = len(results) / len(self._client_manager.all())\n",
    "\n",
    "        # Update the global control variates according to\n",
    "        # global_cv <- global_cv + cv_coeff * aggregated_cv\n",
    "        # where cv_coeff = |S| / N, |S| is the number of clients that participated in the round\n",
    "        # and aggregated_cv = (1 / |S|) * sum_{i in S} (c_i^+ - c_i)\n",
    "        self.global_cv = [\n",
    "            cv + cv_coeff * new_cv for cv, new_cv in zip(self.global_cv, aggregated_cv)\n",
    "        ]\n",
    "\n",
    "\n",
    "        # Update the global model parameters\n",
    "        # new_parameters = current_parameters + aggregated_parameters\n",
    "        # where current_parameters are the parameters of the global model before the round\n",
    "        # and aggregated_parameters = (1 / |S|) * sum_{i in S} (w_i^+ - w)\n",
    "        current_parameters = parameters_to_ndarrays(self.parameters)\n",
    "        new_parameters = [\n",
    "            param + update for param, update in zip(current_parameters, aggregated_parameters)\n",
    "        ]\n",
    "\n",
    "        new_parameters = ndarrays_to_parameters(new_parameters)\n",
    "\n",
    "        return new_parameters, aggregated_results[1], (results, failures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebdbc17",
   "metadata": {},
   "source": [
    "We are now ready for the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "139ad0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the model and get the parameters\n",
    "params = get_parameters(SmallCNN())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# The `evaluate` function will be called by Flower after every round\n",
    "def evaluate(\n",
    "        server_round: int,\n",
    "        parameters: list[np.ndarray],\n",
    "        config: dict[str, Scalar],\n",
    "    ) -> Optional[Tuple[float, dict[str, Scalar]]]:\n",
    "    \n",
    "    net = SmallCNN().to(DEVICE)\n",
    "    _, _, testloader = load_datasets(   \n",
    "        partition_id=0,                         # specify partition ID to load\n",
    "        partition_method=PARTITION_METHOD,      # Method to partition the dataset\n",
    "        partitioner_kwargs=PARTITIONER_KWARGS,  # Parameters for the partitioner\n",
    "        batch_size=BATCH_SIZE,                  # Batch size for the DataLoader    \n",
    "        cache_dir=DATADIR                       # Directory to cache the datasets\n",
    "    )\n",
    "    set_parameters(net, parameters)  # Update model with the latest parameters\n",
    "    loss, accuracy = test(\n",
    "        net=net, \n",
    "        device=DEVICE, \n",
    "        testloader=testloader, \n",
    "        criterion=criterion,\n",
    "        )\n",
    "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
    "    return loss, {\"accuracy\": accuracy}\n",
    "\n",
    "\n",
    "\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    # Create FedAvg strategy\n",
    "    #strategy = ScaffoldStrategy(\n",
    "    #    total_num_clients=NUM_PARTITIONS,       # Total number of clients\n",
    "    #    fraction_fit=1.0,                       # Use all clients for training, C\n",
    "    #    fraction_evaluate=0.5,                  # Use 50% of clients for evaluation\n",
    "    #    min_fit_clients=10,                     # Minimum number of clients to train\n",
    "    #    min_evaluate_clients=5,                 # Minimum number of clients to evaluate\n",
    "    #    min_available_clients=NUM_PARTITIONS,   # Minimum number of clients available (enforce all clients to be available)\n",
    "    #    evaluate_fn=evaluate,                   # Pass the evaluation function\n",
    "    #)\n",
    "    strategy = FedAvg(\n",
    "        fraction_fit=1.0,                       # Use all clients for training, C\n",
    "        fraction_evaluate=0.5,                  # Use 50% of clients for evaluation\n",
    "        min_fit_clients=10,                     # Minimum number of clients to train\n",
    "        min_evaluate_clients=5,                 # Minimum number of clients to evaluate\n",
    "        min_available_clients=NUM_PARTITIONS,   # Minimum number of clients available (enforce all clients to be available)\n",
    "        evaluate_fn=evaluate,                   # Pass the evaluation function\n",
    "    )\n",
    "\n",
    "    server = ScaffoldServer(strategy=strategy)\n",
    "\n",
    "    # Configure the server for 3 rounds of training\n",
    "    config = ServerConfig(num_rounds=2)\n",
    "    return ServerAppComponents(server=server, config=config)\n",
    "\n",
    "# Create the ServerApp\n",
    "server = ServerApp(server_fn=server_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85531a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=2, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[36m(ClientAppActor pid=27680)\u001b[0m Using the latest cached version of the dataset since cifar10 couldn't be found on the Hugging Face Hub\n",
      "\u001b[36m(ClientAppActor pid=27680)\u001b[0m Found the latest cached dataset configuration 'plain_text' at c:\\Users\\Phill\\Documents\\School\\MSc\\3. Sem\\Federated Learning\\FedLearning-Final\\data\\flower_dataset\\cifar10\\plain_text\\0.0.0\\0b2714987fa478483af9968de7c934580d0bb9a2 (last modified on Wed Jun  4 13:48:33 2025).\n",
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 2.3030722991676087, {'accuracy': 0.0991}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 2.3030722991676087 / accuracy 0.0991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=34104)\u001b[0m Using the latest cached version of the dataset since cifar10 couldn't be found on the Hugging Face Hub\n",
      "\u001b[36m(ClientAppActor pid=34104)\u001b[0m Found the latest cached dataset configuration 'plain_text' at c:\\Users\\Phill\\Documents\\School\\MSc\\3. Sem\\Federated Learning\\FedLearning-Final\\data\\flower_dataset\\cifar10\\plain_text\\0.0.0\\0b2714987fa478483af9968de7c934580d0bb9a2 (last modified on Wed Jun  4 13:48:33 2025).\n",
      "\u001b[36m(ClientAppActor pid=31516)\u001b[0m Using the latest cached version of the dataset since cifar10 couldn't be found on the Hugging Face Hub\n",
      "\u001b[36m(ClientAppActor pid=31516)\u001b[0m Found the latest cached dataset configuration 'plain_text' at c:\\Users\\Phill\\Documents\\School\\MSc\\3. Sem\\Federated Learning\\FedLearning-Final\\data\\flower_dataset\\cifar10\\plain_text\\0.0.0\\0b2714987fa478483af9968de7c934580d0bb9a2 (last modified on Wed Jun  4 13:48:33 2025).\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 2.2482746421911153, {'accuracy': 0.1719}, 83.19535709999036)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 2.2482746421911153 / accuracy 0.1719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, 2.046463131904602, {'accuracy': 0.2076}, 149.09314500004984)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 2.046463131904602 / accuracy 0.2076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 2 round(s) in 150.79s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 2.2540293767534454\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 1.9709022027604721\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 0: 2.3030722991676087\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 2.2482746421911153\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 2.046463131904602\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(0, 0.0991), (1, 0.1719), (2, 0.2076)]}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[36m(ClientAppActor pid=26908)\u001b[0m Using the latest cached version of the dataset since cifar10 couldn't be found on the Hugging Face Hub\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=26908)\u001b[0m Found the latest cached dataset configuration 'plain_text' at c:\\Users\\Phill\\Documents\\School\\MSc\\3. Sem\\Federated Learning\\FedLearning-Final\\data\\flower_dataset\\cifar10\\plain_text\\0.0.0\\0b2714987fa478483af9968de7c934580d0bb9a2 (last modified on Wed Jun  4 13:48:33 2025).\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "NUM_PARTITIONS = 10  # Number of partitions (clients)\n",
    "backend_config = {\n",
    "    #\"ray_init_args\": {\n",
    "    #    \"num_cpus\": 1,\n",
    "    #    \"num_gpus\": 1,\n",
    "    #},\n",
    "    \"client_resources\": {\n",
    "        \"num_cpus\": 2,\n",
    "        \"num_gpus\": 0.2,\n",
    "    }\n",
    "}\n",
    "run_simulation(\n",
    "    server_app=server, client_app=client, num_supernodes=NUM_PARTITIONS, backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a59d38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FLenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
