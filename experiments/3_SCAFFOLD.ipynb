{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "095c5c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import List, Tuple, Optional, Union, Dict\n",
    "import os\n",
    "from pathlib import Path\n",
    "from logging import WARNING, INFO, DEBUG\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim import SGD\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import flwr\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    NDArrays,\n",
    "    Parameters,\n",
    "    Metrics, \n",
    "    Context, \n",
    "    Scalar, \n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    "    )\n",
    "from flwr.common.logger import log\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents, Server\n",
    "from flwr.server.strategy import FedAvg, Strategy\n",
    "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.client_manager import ClientManager, SimpleClientManager\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr_datasets import FederatedDataset\n",
    "\n",
    "from fedlearn.model import SmallCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3e0686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = Path().cwd().parent / \"data\" / \"flower_dataset\"\n",
    "logdir = Path().cwd().parent / \"logs\" / \"scaffold\"\n",
    "\n",
    "if not logdir.exists():\n",
    "    logdir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "002a2a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "Flower 1.18.0 / PyTorch 2.7.0+cu126\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e393fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PARTITIONS = 10 # Number of partitions for the federated dataset same as the number of clients\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "def load_datasets(partition_id: int, num_partitions: int):\n",
    "    #partitioner = \n",
    "    fds = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\": num_partitions}, cache_dir=datadir)\n",
    "    partition = fds.load_partition(partition_id)\n",
    "    # Divide data on each node: 80% train, 20% test\n",
    "    partition_train_test = partition.train_test_split(test_size=0.2, seed=42)\n",
    "    pytorch_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "\n",
    "    def apply_transforms(batch):\n",
    "        # Instead of passing transforms to CIFAR10(..., transform=transform)\n",
    "        # we will use this function to dataset.with_transform(apply_transforms)\n",
    "        # The transforms object is exactly the same\n",
    "        batch[\"img\"] = [pytorch_transforms(img) for img in batch[\"img\"]]\n",
    "        return batch\n",
    "\n",
    "    partition_train_test = partition_train_test.with_transform(apply_transforms)\n",
    "    trainloader = DataLoader(\n",
    "        partition_train_test[\"train\"], batch_size=BATCH_SIZE, shuffle=True\n",
    "    )\n",
    "    valloader = DataLoader(partition_train_test[\"test\"], batch_size=BATCH_SIZE)\n",
    "    testset = fds.load_split(\"test\").with_transform(apply_transforms)\n",
    "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
    "    return trainloader, valloader, testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbbce0a",
   "metadata": {},
   "source": [
    "### Define Scaffold Optimizer\n",
    "\n",
    "Recall that the local update in Scaffold is given by\n",
    "\n",
    "$$\n",
    "w^{(i)} \\gets w^{(i)} - \\eta_l \\left( g_i(w^{(i)}) + c - c_i \\right)\n",
    "$$\n",
    "\n",
    "Which can be seen as a gradient correction to Stochastic Gradient Descent (SGD). We may therefore extend the pytorch ```SGD``` class. We do this by computing the the regular SGD step, then adding the correction manually:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "w^{(i)} &\\gets w^{(i)} - \\eta_l \\, g_i\\left(w^{(i)}\\right) \\\\\n",
    "w^{(i)} &\\gets w^{(i)} - \\eta_l (c - c_i)\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b999b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaffoldOptimizer(SGD):\n",
    "    def __init__(self, params, lr, momentum=0., weight_decay=0.):\n",
    "        super().__init__(params, lr, momentum, weight_decay)\n",
    "\n",
    "    def step_custom(self, global_cv, client_cv):\n",
    "        \"\"\"\n",
    "        Perform a single optimization step.\n",
    "        :param global_cv: Global control variable\n",
    "        :param client_cv: Client control variable\n",
    "        \"\"\"\n",
    "        # compute regular SGD step\n",
    "        #   w <- w - lr * grad\n",
    "        super().step() \n",
    "\n",
    "        # now add the correction term\n",
    "        #   w <- w - lr * (g_cv - c_cv)\n",
    "        device = self.param_groups[0][\"params\"][0].device\n",
    "        for group in self.param_groups:\n",
    "            for param, g_cv, c_cv in zip(group[\"params\"], global_cv, client_cv):\n",
    "                # here we add the correction term to each parameter tensor.\n",
    "                # the alpha value scales the correction term\n",
    "                    g_cv, c_cv = g_cv.to(device), c_cv.to(device)\n",
    "                    param.data.add_(g_cv - c_cv, alpha=-group[\"lr\"]) \n",
    "                #if param.grad is not None:\n",
    "                    #g_cv, c_cv = g_cv.to(device), c_cv.to(device)\n",
    "                    #param.grad.add_(g_cv - c_cv)  #, alpha=-group[\"lr\"]) \n",
    "        #super().step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0954175b",
   "metadata": {},
   "source": [
    "We can now write a function for the local training. In this function, we want simply want to perform gradient corrected SGD updates over the local data for $E$ epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d0b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_scaffold(net: torch.nn.Module, \n",
    "                   device: torch.device, \n",
    "                   trainloader: torch.utils.data.DataLoader,\n",
    "                   criterion: nn.Module,\n",
    "                   num_epochs: int, \n",
    "                   lr: float, \n",
    "                   momentum: float, \n",
    "                   weight_decay: float, \n",
    "                   global_cv: List[torch.Tensor], \n",
    "                   client_cv: List[torch.Tensor],\n",
    "                   ) -> None:\n",
    "    \"\"\"\n",
    "    Function that trains a model using the Scaffold optimization algorithm.\n",
    "    Parameters:\n",
    "        net:            The neural network model to train.\n",
    "        device:         The device to run the training on (CPU or GPU).\n",
    "        trainloader:    DataLoader for the training data.\n",
    "        criterion:      Loss function to use for training.\n",
    "        num_epochs:     Number of epochs to train the model.\n",
    "        lr:             Learning rate for the optimizer.\n",
    "        momentum:       Momentum factor for the optimizer.\n",
    "        weight_decay:   Weight decay (L2 penalty) for the optimizer.\n",
    "        global_cv:      Global control variables for Scaffold.\n",
    "        client_cv:      Client control variables for Scaffold.\n",
    "    \"\"\"\n",
    "    net.to(device)\n",
    "    net.train()\n",
    "    optimizer = ScaffoldOptimizer(\n",
    "        net.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay\n",
    "    )\n",
    "    \n",
    "    for _ in range(num_epochs):\n",
    "        for batch in trainloader:\n",
    "            Xtrain, Ytrain = batch[\"img\"].to(device), batch[\"label\"].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = net(Xtrain)\n",
    "            loss = criterion(output, Ytrain)\n",
    "\n",
    "            # for debugging purposes, exit if loss is NaN\n",
    "            #if torch.isnan(loss):\n",
    "            #    raise ValueError(\"Loss is NaN, check your model and data.\")\n",
    "\n",
    "            loss.backward()\n",
    "            \n",
    "            # Perform a single optimization step with the control variables\n",
    "            optimizer.step_custom(global_cv, client_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436bd857",
   "metadata": {},
   "source": [
    "We will also define a test function, which will be called to evaluate our model. This will give us some metrics to evaluate the performance of the model. As we are working with a classifier, we are interested in both the loss and accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8975daea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net: torch.nn.Module, \n",
    "         device: torch.device, \n",
    "         testloader: torch.utils.data.DataLoader,\n",
    "         criterion: nn.Module,\n",
    "         ) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Function that tests a model on the test dataset.\n",
    "    Parameters:\n",
    "        net:        The neural network model to test.\n",
    "        device:     The device to run the testing on (CPU or GPU).\n",
    "        testloader: DataLoader for the test data.\n",
    "        criterion:  Loss function to use for testing.\n",
    "    Returns:\n",
    "        Tuple containing the average loss and accuracy on the test set.\n",
    "    \"\"\"\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    total_loss = 0.0    # Accumulator for total loss\n",
    "    correct = 0         # tracker for correct predictions\n",
    "    total = 0           # tracker for total predictions\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in testloader:\n",
    "            Xtest, Ytest = batch[\"img\"].to(device), batch[\"label\"].to(device)\n",
    "            output = net(Xtest)\n",
    "            loss = criterion(output, Ytest)\n",
    "\n",
    "            if torch.isnan(loss):\n",
    "                raise ValueError(\"Loss is NaN, check your model and data.\")\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += Ytest.size(0)\n",
    "            correct += predicted.eq(Ytest).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(testloader) # compute the average loss\n",
    "    accuracy = correct / total              # compute the accuracy\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26148887",
   "metadata": {},
   "source": [
    "For the simulation, we will use the flower framework, which was introduced in the _ notebook. To do so, we need to specify both Client and Server classes. We need to consider a couple of things: \n",
    "1. We can inherit the  ```NumPyClient``` class from the flower framework, however we need to remember to convert between ```np.ndarray``` and ```torch.tensor``` before and after local updates.\n",
    "2. We need to specify a ```client.fit()``` method, containing all the logic for the local update. This method has 2 inputs\n",
    "   1. parameters: a list of ```np.ndarray```, containing both global model parameters and global control variates\n",
    "   2. config: dict for specifying training configuration (we will ignore this for now)\n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f6d009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define helper functions to set and get model parameters\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "def set_parameters(net: torch.nn.Module, parameters: List[np.ndarray]) -> None:\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k : torch.tensor(v).to(torch.float32) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "class ScaffoldClient(NumPyClient):\n",
    "    def __init__(self, \n",
    "                 partition_id: int, \n",
    "                 net: torch.nn.Module, \n",
    "                 trainloader: torch.utils.data.DataLoader, \n",
    "                 valloader: torch.utils.data.DataLoader,\n",
    "                 criterion: nn.Module,\n",
    "                 device: torch.device,\n",
    "                 num_epochs: int,\n",
    "                 lr: float,\n",
    "                 momentum: float,\n",
    "                 weight_decay: float,\n",
    "                 save_dir: Optional[str] = None,\n",
    "                 ):\n",
    "        self.partition_id = partition_id\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        self.num_epochs = num_epochs\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        # define directory to save client control variates\n",
    "        if save_dir is None:\n",
    "            save_dir = \"client_cvs\"\n",
    "\n",
    "        # create directory if it does not exist\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        # define the path to save the client control variates\n",
    "        self.save_name = os.path.join(save_dir, f\"client_{self.partition_id}_cv.pt\")\n",
    "\n",
    "        # initialize client control variates\n",
    "        self.client_cv = [torch.zeros(param.shape).to(torch.float32) for param in self.net.state_dict().values()]\n",
    "\n",
    "\n",
    "    # Here is where all the training logic and control variate updates happen\n",
    "    def fit(self, parameters: List[np.ndarray], config: dict) -> Tuple[List[np.ndarray], int, dict]:\n",
    "\n",
    "        # the global parameters are packed together with the global control variates\n",
    "        # in the form [params, global_cv]. we start by separating them\n",
    "        params = parameters[:len(parameters) // 2]          # list of np.ndarray\n",
    "        global_cv = parameters[len(parameters) // 2:]       # list of np.ndarray\n",
    "\n",
    "        # load the current global model:\n",
    "        set_parameters(self.net, params)\n",
    "\n",
    "        # load client control variates, if they exist:\n",
    "        if os.path.exists(self.save_name):\n",
    "            self.client_cv = torch.load(self.save_name)     # list of torch.tensor\n",
    "\n",
    "        # convert global control variates to tensors\n",
    "        global_cv_torch = [torch.tensor(cv).to(torch.float32) for cv in global_cv]  # list of torch.tensor\n",
    "\n",
    "        # call the training function\n",
    "        train_scaffold(\n",
    "            net=self.net,\n",
    "            device=self.device,\n",
    "            trainloader=self.trainloader,\n",
    "            criterion=self.criterion,\n",
    "            num_epochs=self.num_epochs,\n",
    "            lr=self.lr,\n",
    "            momentum=self.momentum,\n",
    "            weight_decay=self.weight_decay,\n",
    "            global_cv=global_cv_torch,          # passing list of torch.tensor\n",
    "            client_cv=self.client_cv            # passing list of torch.tensor\n",
    "        )\n",
    "\n",
    "        # update the client control variates\n",
    "        yi = get_parameters(self.net)           # list of np.ndarray\n",
    "\n",
    "        # compute coefficient for the control variates\n",
    "        # 1 / (K * eta) where K is the number of backward passes (num_epochs * len(trainloader))\n",
    "        coeff = 1. / (self.num_epochs * len(self.trainloader) * self.lr) \n",
    "\n",
    "        client_cv = [cv.numpy() for cv in self.client_cv]  # list of np.ndarray\n",
    "\n",
    "        # define new list for udated client control variates\n",
    "        client_cv_new = []\n",
    "\n",
    "        # compute client control variate update, list of np.ndarray\n",
    "        for xj, yj, cj, cij in zip(params, yi, global_cv, client_cv):\n",
    "            client_cv_new.append(\n",
    "                cij - cj + coeff * (xj - yj)\n",
    "            ) \n",
    "\n",
    "        # compute server updates\n",
    "        server_update_x = [yj - xj for xj, yj in zip(params, yi)]\n",
    "        server_update_c = [cij_n - cij for cij_n, cij in zip(client_cv_new, client_cv)]\n",
    "\n",
    "        # convert client cvs back to torch tensors\n",
    "        self.client_cv = [torch.tensor(cv).to(torch.float32) for cv in client_cv_new]  \n",
    "\n",
    "        # save the updated client control variates\n",
    "        torch.save(self.client_cv, self.save_name)\n",
    "\n",
    "        #concatenate server updates\n",
    "        server_update = server_update_x + server_update_c\n",
    "\n",
    "        return server_update, len(self.trainloader.dataset), {}\n",
    "\n",
    "\n",
    "\n",
    "    def evaluate(self, parameters: List[np.ndarray], config: dict) -> Tuple[float, int, dict]:\n",
    "        set_parameters(self.net, parameters)\n",
    "        avg_loss, accuracy = test(\n",
    "            net=self.net,\n",
    "            device=self.device,\n",
    "            testloader=self.valloader,\n",
    "            criterion=self.criterion\n",
    "        )\n",
    "        return float(avg_loss), len(self.valloader), {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7644bf3c",
   "metadata": {},
   "source": [
    "Now that we have the flower client defined, we need to define a constructor function which the flower framework can use to instatiate clients as it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fc2badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_fn(context: Context) -> Client:\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "    trainloader, valloader, _ = load_datasets(partition_id, num_partitions)\n",
    "\n",
    "    net = SmallCNN().to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Define hyperparameters for training\n",
    "    num_epochs = 5\n",
    "    lr = 1e-4\n",
    "    momentum = 0.\n",
    "    weight_decay = 0.\n",
    "\n",
    "    return ScaffoldClient(\n",
    "        partition_id=partition_id,\n",
    "        net=net,\n",
    "        trainloader=trainloader,\n",
    "        valloader=valloader,\n",
    "        criterion=criterion,\n",
    "        device=DEVICE,\n",
    "        num_epochs=num_epochs,\n",
    "        lr=lr,\n",
    "        momentum=momentum,\n",
    "        weight_decay=weight_decay,\n",
    "        save_dir=\"client_cvs\"\n",
    "    ).to_client()\n",
    "\n",
    "\n",
    "client = ClientApp(client_fn=client_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661d41df",
   "metadata": {},
   "source": [
    "We also need to implement a custom strategy. We can inherit the ```FedAvg``` class. All we need to do is redefine the ```aggregate_fit()``` method. This method must take the following as input:\n",
    "1. server_round: the current round \n",
    "2. results:\n",
    "3. failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53151c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaffoldStrategy(Strategy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        total_num_clients: int,\n",
    "        fraction_fit: float = 1.0,\n",
    "        fraction_evaluate: float = 1.0,\n",
    "        min_fit_clients: int = 2,\n",
    "        min_evaluate_clients: int = 2,\n",
    "        min_available_clients: int = 2,\n",
    "        evaluate_fn: Optional[callable] = None,\n",
    "        accept_failures: bool = False,\n",
    "        fit_metrics_aggregation_fn: Optional[callable] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.total_num_clients = total_num_clients\n",
    "        total_num_clients = total_num_clients\n",
    "        self.fraction_fit = fraction_fit\n",
    "        self.fraction_evaluate = fraction_evaluate\n",
    "        self.min_fit_clients = min_fit_clients\n",
    "        self.min_evaluate_clients = min_evaluate_clients\n",
    "        self.min_available_clients = min_available_clients\n",
    "        self.accept_failures = accept_failures\n",
    "        self.fit_metrics_aggregation_fn = fit_metrics_aggregation_fn\n",
    "\n",
    "        self.evaluate_fn = evaluate_fn\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"ScaffoldStrategy\"\n",
    "\n",
    "\n",
    "    def initialize_parameters(\n",
    "        self, client_manager: ClientManager\n",
    "    ) -> Optional[Parameters]:\n",
    "        \"\"\"Initialize global model parameters.\"\"\"\n",
    "        net = SmallCNN()\n",
    "        parameters = get_parameters(net)        \n",
    "        return ndarrays_to_parameters(parameters)\n",
    "\n",
    "\n",
    "    def configure_fit(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
    "        \"\"\"Configure the next round of training.\"\"\"\n",
    "\n",
    "        config = {}\n",
    "        fit_ins = FitIns(parameters, config)\n",
    "\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_fit_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "\n",
    "        fit_configurations = [(client, fit_ins) for client in clients]\n",
    "        \n",
    "        return fit_configurations\n",
    "\n",
    "\n",
    "    def aggregate_fit(self, \n",
    "                      server_round: int, \n",
    "                      results: List[Tuple[ClientProxy, FitRes]],\n",
    "                      failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "                      ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        \"\"\"\n",
    "        aggregation method for Scaffold strategy.\n",
    "        \"\"\"\n",
    "        if not results:\n",
    "            return None, {}\n",
    "        if not self.accept_failures and failures:\n",
    "            return None, {}\n",
    "        \n",
    "        combined_parameters = [\n",
    "            parameters_to_ndarrays(fit_res.parameters) for _, fit_res in results\n",
    "        ]\n",
    "\n",
    "        len_combined_parameters = len(combined_parameters[0]) # combined number of model parameters and control variates\n",
    "\n",
    "        num_samples_all = [fit_res.num_examples for _, fit_res in results]  # number of training samples from each client\n",
    "\n",
    "        # The \"aggregate()\" function expects a list of tuples, where each tuple contains\n",
    "        # the local parameters and the number of samples for that client.\n",
    "        aggregation_inputs_parameters = [\n",
    "            (local_params[:len_combined_parameters // 2], num_samples) \n",
    "            for local_params, num_samples in zip(combined_parameters, num_samples_all)\n",
    "        ]\n",
    "        \n",
    "        parameters_aggregated = aggregate(aggregation_inputs_parameters)\n",
    "\n",
    "        aggregation_inputs_cv = [\n",
    "            (local_params[len_combined_parameters // 2:], num_samples) \n",
    "            for local_params, num_samples in zip(combined_parameters, num_samples_all)\n",
    "        ]\n",
    "\n",
    "        cv_aggregated = aggregate(aggregation_inputs_cv)\n",
    "\n",
    "        metrics_aggregated = {}\n",
    "        if self.fit_metrics_aggregation_fn is not None:\n",
    "            fit_metrics = [\n",
    "                (fit_res.num_examples, fit_res.metrics)\n",
    "                for _, fit_res in results\n",
    "            ]\n",
    "            metrics_aggregated = self.fit_metrics_aggregation_fn(fit_metrics)\n",
    "        elif server_round == 1:\n",
    "            log(WARNING, \"No fit_metrics_aggregation_fn provided\")\n",
    "        \n",
    "\n",
    "        return (\n",
    "            ndarrays_to_parameters(parameters_aggregated + cv_aggregated),\n",
    "            metrics_aggregated,\n",
    "        )\n",
    "\n",
    "\n",
    "    def configure_evaluate(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
    "        \"\"\"Configure the next round of evaluation.\"\"\"\n",
    "        if self.fraction_evaluate == 0.0:\n",
    "            return []\n",
    "        config = {}\n",
    "        evaluate_ins = EvaluateIns(parameters, config)\n",
    "\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_evaluation_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "\n",
    "        # Return client/config pairs\n",
    "        return [(client, evaluate_ins) for client in clients]\n",
    "\n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
    "\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        loss_aggregated = weighted_loss_avg(\n",
    "            [\n",
    "                (evaluate_res.num_examples, evaluate_res.loss)\n",
    "                for _, evaluate_res in results\n",
    "            ]\n",
    "        )\n",
    "        metrics_aggregated = {}\n",
    "        return loss_aggregated, metrics_aggregated\n",
    "\n",
    "\n",
    "    # method for evaluating the global model\n",
    "    def evaluate(\n",
    "        self, server_round: int, parameters: Parameters\n",
    "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        \"\"\"Evaluate global model parameters using an evaluation function.\"\"\"\n",
    "        if self.evaluate_fn is None:\n",
    "            return None\n",
    "            # If an evaluation function is provided, use it\n",
    "        parameters_ndarray = parameters_to_ndarrays(parameters)\n",
    "        eval_res = self.evaluate_fn(server_round, parameters_ndarray, {})\n",
    "        if eval_res is None:\n",
    "            return None\n",
    "        loss, metrics = eval_res\n",
    "        return loss, metrics\n",
    "\n",
    "\n",
    "    # boilerplate code\n",
    "    def num_fit_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Return sample size and required number of clients.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_fit)\n",
    "        return max(num_clients, self.min_fit_clients), self.min_available_clients\n",
    "\n",
    "\n",
    "    # boilerplate code\n",
    "    def num_evaluation_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Use a fraction of available clients for evaluation.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_evaluate)\n",
    "        return max(num_clients, self.min_evaluate_clients), self.min_available_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f172f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.server.server import FitResultsAndFailures, fit_clients\n",
    "\n",
    "def concat_params(parameters: Parameters, global_cv: List[np.ndarray]) -> Parameters:\n",
    "    \"\"\"\n",
    "    Concatenate model parameters and global control variates.\n",
    "    \"\"\"\n",
    "    parameters_ndarrays = parameters_to_ndarrays(parameters)\n",
    "    parameters_ndarrays.extend(global_cv)\n",
    "    return ndarrays_to_parameters(parameters_ndarrays)\n",
    "\n",
    "class ScaffoldServer(Server):\n",
    "\n",
    "    def __init__(self, \n",
    "                 strategy: Strategy, \n",
    "                 client_manager: ClientManager = SimpleClientManager(),\n",
    "                 ) -> None:\n",
    "        super().__init__(strategy=strategy, client_manager=client_manager)\n",
    "        \n",
    "        self.global_cv: List[np.ndarray] = []  # Global control variates for Scaffold\n",
    "    \n",
    "    def _get_initial_parameters(\n",
    "        self, server_round: int, timeout: Optional[float]\n",
    "        ) -> Parameters: \n",
    "        \n",
    "        parameters = self.strategy.initialize_parameters(self.client_manager)\n",
    "\n",
    "        if parameters is not None:\n",
    "            log(INFO, \"Using initial parameters provided by strategy\")\n",
    "\n",
    "            self.global_cv = [\n",
    "                np.zeros_like(param, dtype=np.float32) for param in parameters_to_ndarrays(parameters)\n",
    "            ]\n",
    "\n",
    "            return parameters\n",
    "        \n",
    "        log(WARNING, \"No initial parameters provided by strategy, shutting down\")\n",
    "        self.disconnect_all_clients()\n",
    "\n",
    "\n",
    "    def fit_round(\n",
    "            self,\n",
    "            server_round: int,\n",
    "            timeout: Optional[float],\n",
    "            ) -> Optional[Tuple[Optional[Parameters], Dict[str, Scalar], FitResultsAndFailures]]:\n",
    "        \n",
    "        # define client instructions to be passed to \"fit_clients\" function\n",
    "        client_instructions = self.strategy.configure_fit(\n",
    "            server_round=server_round,\n",
    "            parameters=concat_params(self.parameters, self.global_cv),\n",
    "            client_manager=self._client_manager,\n",
    "        )\n",
    "\n",
    "        # if no clients are selected, return None\n",
    "        if not client_instructions:\n",
    "            log(INFO, f\"fit_round {server_round}: no clients selected.\")\n",
    "            return None\n",
    "        \n",
    "        log(\n",
    "            DEBUG,\n",
    "            f\"fit_round {server_round}: selected {len(client_instructions)} clients.\",\n",
    "        )\n",
    "\n",
    "        # Call the \"fit_clients\" function to perform the training on selected clients\n",
    "        results, failures = fit_clients(\n",
    "            client_instructions=client_instructions,\n",
    "            max_workers=self.max_workers,\n",
    "            timeout=timeout,\n",
    "            group_id=server_round,\n",
    "        )\n",
    "\n",
    "        log(DEBUG,\n",
    "            f\"fit_round {server_round}: received {len(results)} results and {len(failures)} failures.\",\n",
    "        )\n",
    "\n",
    "        # Aggregate the results from the clients\n",
    "        aggregated_results = self.strategy.aggregate_fit(\n",
    "            server_round=server_round,\n",
    "            results=results,\n",
    "            failures=failures,\n",
    "        )\n",
    "\n",
    "        # Extract the aggregated parameters and control variates\n",
    "        aggregated_results_combined = []\n",
    "        if aggregated_results[0] is not None:\n",
    "            aggregated_results_combined = parameters_to_ndarrays(aggregated_results[0])\n",
    "\n",
    "        # Split the aggregated results into model parameters and control variates\n",
    "        aggregated_parameters = aggregated_results_combined[:len(aggregated_results_combined) // 2] # model parameters\n",
    "        aggregated_cv = aggregated_results_combined[len(aggregated_results_combined) // 2:]         # control variates\n",
    "\n",
    "        # define the update coefficient for the control variates\n",
    "        cv_coeff = len(results) / len(self._client_manager.all())\n",
    "\n",
    "        # Update the global control variates according to\n",
    "        # global_cv <- global_cv + cv_coeff * aggregated_cv\n",
    "        # where cv_coeff = |S| / N, |S| is the number of clients that participated in the round\n",
    "        # and aggregated_cv = (1 / |S|) * sum_{i in S} (c_i^+ - c_i)\n",
    "        self.global_cv = [\n",
    "            cv + cv_coeff * new_cv for cv, new_cv in zip(self.global_cv, aggregated_cv)\n",
    "        ]\n",
    "\n",
    "\n",
    "        # Update the global model parameters\n",
    "        # new_parameters = current_parameters + aggregated_parameters\n",
    "        # where current_parameters are the parameters of the global model before the round\n",
    "        # and aggregated_parameters = (1 / |S|) * sum_{i in S} (w_i^+ - w)\n",
    "        current_parameters = parameters_to_ndarrays(self.parameters)\n",
    "        new_parameters = [\n",
    "            param + update for param, update in zip(current_parameters, aggregated_parameters)\n",
    "        ]\n",
    "\n",
    "        new_parameters = ndarrays_to_parameters(new_parameters)\n",
    "\n",
    "        return new_parameters, aggregated_results[1], (results, failures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebdbc17",
   "metadata": {},
   "source": [
    "We are now ready for the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "139ad0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the model and get the parameters\n",
    "params = get_parameters(SmallCNN())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# The `evaluate` function will be called by Flower after every round\n",
    "def evaluate(\n",
    "    server_round: int,\n",
    "    parameters: list[np.ndarray],\n",
    "    config: dict[str, Scalar],\n",
    "    ) -> Optional[Tuple[float, dict[str, Scalar]]]:\n",
    "    \n",
    "    net = SmallCNN().to(DEVICE)\n",
    "    _, _, testloader = load_datasets(0, NUM_PARTITIONS)\n",
    "    set_parameters(net, parameters)  # Update model with the latest parameters\n",
    "    loss, accuracy = test(\n",
    "        net=net, \n",
    "        device=DEVICE, \n",
    "        testloader=testloader, \n",
    "        criterion=criterion,\n",
    "        )\n",
    "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
    "    return loss, {\"accuracy\": accuracy}\n",
    "\n",
    "\n",
    "\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    # Create FedAvg strategy\n",
    "    strategy = ScaffoldStrategy(\n",
    "        total_num_clients=NUM_PARTITIONS,       # Total number of clients\n",
    "        fraction_fit=1.0,                       # Use all clients for training, C\n",
    "        fraction_evaluate=0.5,                  # Use 50% of clients for evaluation\n",
    "        min_fit_clients=10,                     # Minimum number of clients to train\n",
    "        min_evaluate_clients=5,                 # Minimum number of clients to evaluate\n",
    "        min_available_clients=NUM_PARTITIONS,   # Minimum number of clients available (enforce all clients to be available)\n",
    "        evaluate_fn=evaluate,                   # Pass the evaluation function\n",
    "    )\n",
    "\n",
    "    server = ScaffoldServer(strategy=strategy)\n",
    "\n",
    "    # Configure the server for 3 rounds of training\n",
    "    config = ServerConfig(num_rounds=3)\n",
    "    return ServerAppComponents(server=server, config=config)\n",
    "\n",
    "# Create the ServerApp\n",
    "server = ServerApp(server_fn=server_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85531a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=3, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 2.3037926693693898, {'accuracy': 0.1001}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 2.3037926693693898 / accuracy 0.1001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[91mERROR \u001b[0m:     ServerApp thread raised an exception: Loss is NaN, check your model and data.\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Phill\\anaconda3\\envs\\FLenv2\\Lib\\site-packages\\flwr\\simulation\\run_simulation.py\", line 268, in server_th_with_start_checks\n",
      "    updated_context = _run(\n",
      "                      ^^^^^\n",
      "  File \"c:\\Users\\Phill\\anaconda3\\envs\\FLenv2\\Lib\\site-packages\\flwr\\server\\run_serverapp.py\", line 62, in run\n",
      "    server_app(grid=grid, context=context)\n",
      "  File \"c:\\Users\\Phill\\anaconda3\\envs\\FLenv2\\Lib\\site-packages\\flwr\\server\\server_app.py\", line 166, in __call__\n",
      "    start_grid(\n",
      "  File \"c:\\Users\\Phill\\anaconda3\\envs\\FLenv2\\Lib\\site-packages\\flwr\\server\\compat\\app.py\", line 90, in start_grid\n",
      "    hist = run_fl(\n",
      "           ^^^^^^^\n",
      "  File \"c:\\Users\\Phill\\anaconda3\\envs\\FLenv2\\Lib\\site-packages\\flwr\\server\\server.py\", line 492, in run_fl\n",
      "    hist, elapsed_time = server.fit(\n",
      "                         ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Phill\\anaconda3\\envs\\FLenv2\\Lib\\site-packages\\flwr\\server\\server.py\", line 128, in fit\n",
      "    res_cen = self.strategy.evaluate(current_round, parameters=self.parameters)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Phill\\AppData\\Local\\Temp\\ipykernel_35352\\2412519598.py\", line 167, in evaluate\n",
      "    eval_res = self.evaluate_fn(server_round, parameters_ndarray, {})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Phill\\AppData\\Local\\Temp\\ipykernel_35352\\2821112699.py\", line 15, in evaluate\n",
      "    loss, accuracy = test(\n",
      "                     ^^^^^\n",
      "  File \"C:\\Users\\Phill\\AppData\\Local\\Temp\\ipykernel_35352\\4179507703.py\", line 29, in test\n",
      "    raise ValueError(\"Loss is NaN, check your model and data.\")\n",
      "ValueError: Loss is NaN, check your model and data.\n",
      "\n",
      "Exception in thread Thread-3 (server_th_with_start_checks):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Phill\\anaconda3\\envs\\FLenv2\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\Phill\\anaconda3\\envs\\FLenv2\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\Phill\\anaconda3\\envs\\FLenv2\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\Phill\\anaconda3\\envs\\FLenv2\\Lib\\site-packages\\flwr\\simulation\\run_simulation.py\", line 268, in server_th_with_start_checks\n",
      "    updated_context = _run(\n",
      "                      ^^^^^\n",
      "  File \"c:\\Users\\Phill\\anaconda3\\envs\\FLenv2\\Lib\\site-packages\\flwr\\server\\run_serverapp.py\", line 62, in run\n",
      "    server_app(grid=grid, context=context)\n",
      "  File \"c:\\Users\\Phill\\anaconda3\\envs\\FLenv2\\Lib\\site-packages\\flwr\\server\\server_app.py\", line 166, in __call__\n",
      "    start_grid(\n",
      "  File \"c:\\Users\\Phill\\anaconda3\\envs\\FLenv2\\Lib\\site-packages\\flwr\\server\\compat\\app.py\", line 90, in start_grid\n",
      "    hist = run_fl(\n",
      "           ^^^^^^^\n",
      "  File \"c:\\Users\\Phill\\anaconda3\\envs\\FLenv2\\Lib\\site-packages\\flwr\\server\\server.py\", line 492, in run_fl\n",
      "    hist, elapsed_time = server.fit(\n",
      "                         ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Phill\\anaconda3\\envs\\FLenv2\\Lib\\site-packages\\flwr\\server\\server.py\", line 128, in fit\n",
      "    res_cen = self.strategy.evaluate(current_round, parameters=self.parameters)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Phill\\AppData\\Local\\Temp\\ipykernel_35352\\2412519598.py\", line 167, in evaluate\n",
      "  File \"C:\\Users\\Phill\\AppData\\Local\\Temp\\ipykernel_35352\\2821112699.py\", line 15, in evaluate\n",
      "  File \"C:\\Users\\Phill\\AppData\\Local\\Temp\\ipykernel_35352\\4179507703.py\", line 29, in test\n",
      "ValueError: Loss is NaN, check your model and data.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Exception in ServerApp thread",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m NUM_PARTITIONS = \u001b[32m10\u001b[39m  \u001b[38;5;66;03m# Number of partitions (clients)\u001b[39;00m\n\u001b[32m      2\u001b[39m backend_config = {\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mray_init_args\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m      4\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mnum_cpus\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m,\n\u001b[32m      5\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mnum_gpus\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m,\n\u001b[32m      6\u001b[39m     }\n\u001b[32m      7\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mrun_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_app\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_app\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_supernodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNUM_PARTITIONS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackend_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Phill\\anaconda3\\envs\\FLenv2\\Lib\\site-packages\\flwr\\simulation\\run_simulation.py:211\u001b[39m, in \u001b[36mrun_simulation\u001b[39m\u001b[34m(server_app, client_app, num_supernodes, backend_name, backend_config, enable_tf_gpu_growth, verbose_logging)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m enable_tf_gpu_growth:\n\u001b[32m    203\u001b[39m     warn_deprecated_feature_with_example(\n\u001b[32m    204\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassing `enable_tf_gpu_growth=True` is deprecated.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    205\u001b[39m         example_message=\u001b[33m\"\u001b[39m\u001b[33mInstead, set the `TF_FORCE_GPU_ALLOW_GROWTH` environment \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    208\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33mflwr.simulation.run_simulationt(...)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    209\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m _ = \u001b[43m_run_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_supernodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_supernodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_app\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_app\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_app\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_app\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackend_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackend_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable_tf_gpu_growth\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable_tf_gpu_growth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_logging\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose_logging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexit_event\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEventType\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPYTHON_API_RUN_SIMULATION_LEAVE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Phill\\anaconda3\\envs\\FLenv2\\Lib\\site-packages\\flwr\\simulation\\run_simulation.py:510\u001b[39m, in \u001b[36m_run_simulation\u001b[39m\u001b[34m(num_supernodes, exit_event, client_app, server_app, backend_name, backend_config, client_app_attr, server_app_attr, server_app_run_config, app_dir, flwr_dir, run, enable_tf_gpu_growth, verbose_logging, is_app)\u001b[39m\n\u001b[32m    506\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m asyncio_loop_running:\n\u001b[32m    507\u001b[39m         \u001b[38;5;66;03m# Set logger propagation to False to prevent duplicated log output in Colab.\u001b[39;00m\n\u001b[32m    508\u001b[39m         logger = set_logger_propagation(logger, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m510\u001b[39m     updated_context = \u001b[43m_main_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m updated_context\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Phill\\anaconda3\\envs\\FLenv2\\Lib\\site-packages\\flwr\\simulation\\run_simulation.py:408\u001b[39m, in \u001b[36m_main_loop\u001b[39m\u001b[34m(num_supernodes, backend_name, backend_config_stream, app_dir, is_app, enable_tf_gpu_growth, run, exit_event, flwr_dir, client_app, client_app_attr, server_app, server_app_attr, server_app_run_config)\u001b[39m\n\u001b[32m    406\u001b[39m         serverapp_th.join()\n\u001b[32m    407\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m server_app_thread_has_exception.is_set():\n\u001b[32m--> \u001b[39m\u001b[32m408\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mException in ServerApp thread\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    410\u001b[39m log(DEBUG, \u001b[33m\"\u001b[39m\u001b[33mStopping Simulation Engine now.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    411\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m updated_context\n",
      "\u001b[31mRuntimeError\u001b[39m: Exception in ServerApp thread"
     ]
    }
   ],
   "source": [
    "NUM_PARTITIONS = 10  # Number of partitions (clients)\n",
    "backend_config = {\n",
    "    \"ray_init_args\": {\n",
    "        \"num_cpus\": 1,\n",
    "        \"num_gpus\": 1,\n",
    "    }\n",
    "}\n",
    "run_simulation(\n",
    "    server_app=server, client_app=client, num_supernodes=NUM_PARTITIONS, backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514d5de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FLenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
